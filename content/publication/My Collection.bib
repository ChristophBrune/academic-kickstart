@article{Boink2019,
abstract = {In an inhomogeneously illuminated photoacoustic image, important information like vascular geometry is not readily available when only the initial pressure is reconstructed. To obtain the desired information, algorithms for image segmentation are often applied as a post-processing step. In this work, we propose to jointly acquire the photoacoustic reconstruction and segmentation, by modifying a recently developed partially learned algorithm based on a convolutional neural network. We investigate the stability of the algorithm against changes in initial pressures and photoacoustic system settings. These insights are used to develop an algorithm that is robust to input and system settings. Our approach can easily be applied to other imaging modalities and can be modified to perform other high-level tasks different from segmentation. The method is validated on challenging synthetic and experimental photoacoustic tomography data in limited angle and limited view scenarios. It is computationally less expensive than classical iterative methods and enables higher quality reconstructions and segmentations than state-of-the-art learned and non-learned methods.},
archivePrefix = {arXiv},
arxivId = {1906.07499},
author = {Boink, Yoeri E. and Manohar, Srirang and Brune, Christoph},
doi = {10.1109/TMI.2019.2922026},
eprint = {1906.07499},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Boink, Manohar, Brune - 2019 - A Partially Learned Algorithm for Joint Photoacoustic Reconstruction and Segmentation(2).pdf:pdf},
issn = {0278-0062},
journal = {IEEE Transactions on Medical Imaging},
month = {jun},
pages = {1--1},
title = {{A Partially Learned Algorithm for Joint Photoacoustic Reconstruction and Segmentation}},
url = {http://arxiv.org/abs/1906.07499},
year = {2019}
}
@inproceedings{Boink2019a,
author = {Boink, Yoeri and Brune, Christoph and Manohar, Srirang},
booktitle = {Photons Plus Ultrasound: Imaging and Sensing 2019},
doi = {10.1117/12.2507446},
editor = {Oraevsky, Alexander A. and Wang, Lihong V.},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Boink, Brune, Manohar - 2019 - Robustness of a partially learned photoacoustic reconstruction algorithm.pdf:pdf},
isbn = {9781510623989},
month = {mar},
pages = {47},
publisher = {SPIE},
title = {{Robustness of a partially learned photoacoustic reconstruction algorithm}},
volume = {10878},
year = {2019}
}
@article{Tovey2018,
abstract = {In this paper we propose a new joint model for the reconstruction of tomography data under limited angle sampling regimes. In many applications of Tomography, e.g. Electron Microscopy and Mammography, physical limitations on acquisition lead to regions of data which cannot be sampled. Depending on the severity of the restriction, reconstructions can contain severe, characteristic, artefacts. Our model aims to address these artefacts by inpainting the missing data simultaneously with the reconstruction. Numerically, this problem naturally evolves to require the minimisation of a non-convex and non-smooth functional so we review recent work in this topic and extend results to fit an alternating (block) descent framework. We illustrate the effectiveness of this approach with numerical experiments on two synthetic datasets and one Electron Microscopy dataset.},
author = {Tovey, Robert and Benning, Martin and Brune, Christoph and Lagerwerf, Marinus Jan and Collins, Sean Michael and Leary, Rowan K and Midgley, Paul A. and Sch{\"{o}}nlieb, Carola-Bibiane},
doi = {10.1088/1361-6420/aaf2fe},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Tovey et al. - 2019 - Directional sinogram inpainting for limited angle tomography.pdf:pdf},
issn = {0266-5611},
journal = {Inverse Problems},
month = {feb},
number = {2},
pages = {024004},
title = {{Directional sinogram inpainting for limited angle tomography}},
url = {https://iopscience.iop.org/article/10.1088/1361-6420/aaf2fe/pdf},
volume = {35},
year = {2019}
}
@inproceedings{Maki-Petaja2018,
author = {Maki-Petaja, Kaisa and McGeoch, Adam and Yang, Lucy and Hubsch, Annette and McEniery, Carmel and Mir, Fraz and Gajendragadkar, Parag and Ramenatte, Nicola and Anandappa, Gayathri and Brune, Christoph and Boink, Yoeri and Bibiane-Schonlieb, Carola and Meyer, Paul and Bond, Simon and Wilkinson, Ian and Jodrell, Duncan and Cheriyan, Joseph},
booktitle = {Conference Abstract, Artery Research, ARTERY 18, Centro Cultural Vila Flor, Guimar{\~{a}}es, Portugal, 18-20 October 2018},
doi = {10.1016/j.artres.2018.10.082},
issn = {18729312},
month = {dec},
pages = {87--88},
publisher = {No longer published by Elsevier},
title = {{Mechanisms of Vascular Endothelial Growth Factor inhibition induced hypertension}},
volume = {24},
year = {2018}
}
@inproceedings{Boink2018,
abstract = {We replace part of a model-based iterative algorithm with a convolutional neural network in order to improve the quality of tomography reconstructions. We analyse its robustness against uncertainties in the image and uncertainties in system settings. Results are presented for the application of photoacoustic tomography in a limited angle setup.},
author = {Boink, Yoeri E. and van Gils, Stephan A. and Manohar, Srirang and Brune, Christoph},
booktitle = {PAMM, Proceedings in Applied Mathematics and Mechanics, 89th Annual Meeting of the International Association of Applied Mathematics and Mechanics (GAMM)},
doi = {10.1002/pamm.201800222},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Boink et al. - 2018 - Sensitivity of a partially learned model-based reconstruction algorithm.pdf:pdf},
issn = {16177061},
month = {dec},
number = {1},
pages = {e201800222},
title = {{Sensitivity of a partially learned model-based reconstruction algorithm}},
url = {https://onlinelibrary.wiley.com/doi/epdf/10.1002/pamm.201800222},
volume = {18},
year = {2018}
}
@inproceedings{Zeune2018,
author = {Zeune, Leonie and van Dalum, Guus and Nanou, Afroditi and de Wit, Sanne and Andree, Kiki and Swennenhuis, Joost F and Terstappen, Leon and Brune, Christoph},
booktitle = {Conference Abstract, Clinical {\&} Experimental Metastasis, 11th International Symposium on Minimal Residual Disease, 3-5 May 2018, Montpellier, France},
doi = {10.1007/s10585-018-9911-0},
editor = {Alix-Panabi{\`{e}}res, C. and Pantel, K.},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Zeune et al. - 2018 - Deep learning to identify circulating tumor cells by ACCEPT.pdf:pdf},
issn = {0262-0898},
month = {jul},
number = {3},
pages = {192--193},
title = {{Deep learning to identify circulating tumor cells by ACCEPT}},
volume = {35},
year = {2018}
}
@article{Zeune2018a,
abstract = {For using counts of circulating tumor cells (CTCs) in the clinic to aid a physician's decision, its reported values will need to be accurate and comparable between institutions. Many technologies have become available to enumerate and characterize CTCs, thereby showing a large range of reported values. Here we introduce an Open Source CTC scoring tool to enable comparison of different reviewers and facilitate the reach of a consensus on assigning objects as CTCs. One hundred images generated from two different platforms were used to assess concordance between 15 reviewers and an expert panel. Large differences were observed between reviewers in assigning objects as CTCs urging the need for computer recognition of CTCs. A demonstration of a deep learning approach on the 100 images showed the promise of this technique for future CTC enumeration.},
author = {Zeune, Leonie L. and Wit, Sanne and Berghuis, A.M. Sofie and IJzerman, Maarten J. and Terstappen, Leon W.M.M. and Brune, Christoph},
doi = {10.1002/cyto.a.23576},
file = {:Users/brunec/work/papers/finished papers/2018/Zeune{\_}et{\_}al-2018-Cytometry{\_}Part{\_}A.pdf:pdf},
issn = {1552-4922},
journal = {Cytometry Part A},
keywords = {Agreement,CTC,consensus,deep learning,definition,experts,ground truth,reviewers,scoring},
month = {dec},
number = {12},
pages = {1202--1206},
title = {{How to Agree on a CTC: Evaluating the Consensus in Circulating Tumor Cell Scoring}},
url = {https://onlinelibrary.wiley.com/doi/epdf/10.1002/cyto.a.23576},
volume = {93},
year = {2018}
}
@inproceedings{DAngremont2018,
abstract = {Introduction In patients with drug-resistant focal epilepsy, surgery can be considered. The goal is to remove the epileptogenic tissue, while sparing the eloquent cortex. Prior to surgery, a prolonged electroencephalography (ECoG) recording can assist in the delineation of epileptogenic tissue and functionality of the surrounding cortex. During these recordings, Single Pulse Electrical Stimulation (SPES) of the intra-cranial electrodes is performed to evoke pathological responses from the epileptogenic tissue, which occur {\textgreater}100 ms after stimulation. These responses are called delayed responses (DR). In the UMC Utrecht, they are visually analyzed by use of time-frequency images from approximately 2 s. around stimulation. Each image is scored by two human observers on the presence of an evoked DR in three different frequency bands, namely Spikes (S, 10–80 Hz), Ripples (R, 80–250 Hz) and Fast Ripples (F, 250–510 Hz). This visual analysis is very labor intensive. Therefore, we trained a Support Vector Machine (SVM) and a Convolutional Neural Network (CNN) to mimic the human observer in scoring the images. Methods The training data consisted of 47,197 images from 15 patients, with the consensus of two human observers as ground truth. The algorithms were tested on a total of 11,394 images from 4 other patients. For the SVM, 9 features were defined and extracted from each image. The CNN used the whole image as an input. Classification was based on 5 different outputs. F1 scores were calculated for all classes separately. Results The CNN achieved an average F1 score of 0.55. The SVM did slightly better with 0.60. Sensitivity and precision for the DRs were 0.88 and 0.65 for the SVM vs 0.96 and 0.42 for the CNN. Conclusion Two machine learning algorithms were trained to score time-frequency responses of SPES. Both models showed a high sensitivity but a lower specificity for DRs. This was more pronounced for the CNN than for the SVM. Nonetheless, a drastical decrease in time and effort needed for the analysis of SPES is already achieved. More data of the underrepresented classes should be created for the algorithms to improve. The algorithms will be applied to additional patient data to see whether the agreement with human observers is comparable with the inter-rater agreement. Future research will aim at relating the found DRs to the seizure onset zone.},
author = {D'Angremont, Emile and Huiskamp, Geertjan J. and Leijten, Frans S. and Brune, Christoph and van Putten, Michel J.},
booktitle = {Conference Abstract, Clinical Neurophysiology, 31st International Congress of Clinical Neurophysiology (ICCN) of the IFCN, May 1–6, 2018, Washington, DC, USA},
doi = {10.1016/j.clinph.2018.04.317},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/d'Angremont et al. - 2018 - F154. Machine learning for the analysis of single pulse stimulation in electrocorticography.pdf:pdf},
issn = {13882457},
month = {may},
pages = {e125},
publisher = {Elsevier},
title = {{Machine learning for the analysis of single pulse stimulation in electrocorticography}},
volume = {129},
year = {2018}
}
@article{Lucka2017,
abstract = {This paper discusses the properties of certain risk estimators that recently regained popularity for choosing regularization parameters in ill-posed problems, in particular for sparsity regularization. They apply Stein's unbiased risk estimator (SURE) to estimate the risk in either the space of the unknown variables or in the data space. We will call the latter PSURE in order to distinguish the two different risk functions. It seems intuitive that SURE is more appropriate for ill-posed problems, since the properties in the data space do not tell much about the quality of the reconstruction. We provide theoretical studies of both approaches for linear Tikhonov regularization in a finite dimensional setting and estimate the quality of the risk estimators, which also leads to asymptotic convergence results as the dimension of the problem tends to infinity. Unlike previous works which studied single realizations of image processing problems with a very low degree of ill-posedness, we are interested in the statistical behaviour of the risk estimators for increasing ill-posedness. Interestingly, our theoretical results indicate that the quality of the SURE risk can deteriorate asymptotically for ill-posed problems, which is confirmed by an extensive numerical study. The latter shows that in many cases the SURE estimator leads to extremely small regularization parameters, which obviously cannot stabilize the reconstruction. Similar but less severe issues with respect to robustness also appear for the PSURE estimator, which in comparison to the rather conservative discrepancy principle leads to the conclusion that regularization parameter choice based on unbiased risk estimation is not a reliable procedure for ill-posed problems. A similar numerical study for sparsity regularization demonstrates that the same issue appears in non-linear variational regularization approaches.},
archivePrefix = {arXiv},
arxivId = {1701.04970},
author = {Lucka, Felix and Proksch, Katharina and Brune, Christoph and Bissantz, Nicolai and Burger, Martin and Dette, Holger and W{\"{u}}bbeling, Frank},
doi = {10.3934/ipi.2018047},
eprint = {1701.04970},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Lucka et al. - 2018 - RISK ESTIMATORS FOR CHOOSING REGULARIZATION PARAMETERS IN ILL-POSED PROBLEMS - PROPERTIES AND LIMITATIONS Christop.pdf:pdf},
issn = {1930-8345},
journal = {Inverse Problems {\&} Imaging},
keywords = {Stein's method,discrepancy principle,ll-posed  problems,regularization,regularization  parameter  choice,risk  estimators},
mendeley-tags = {regularization},
month = {oct},
number = {5},
pages = {1121--1155},
publisher = {American Institute of Mathematical Sciences},
title = {{Risk estimators for choosing regularization parameters in ill-posed problems - properties and limitations}},
url = {http://arxiv.org/abs/1701.04970},
volume = {12},
year = {2018}
}
@article{Nanou2018,
abstract = {Purpose: The presence of Circulating Tumor Cells (CTCs) in Castration-Resistant Prostate Cancer (CRPC) patients is associated with poor prognosis. In this study, we evaluated the association of clinical outcome in 129 CRPC patients with CTCs, tumor-derived Extracellular Vesicles (tdEVs) and plasma levels of total (CK18) and caspase-cleaved cytokeratin 18 (ccCK18). Experimental Design: CTCs and tdEVs were isolated with the CellSearch system and automatically enumerated. Cut-off values dichotomizing patients into favorable and unfavorable groups of overall survival were set on a retrospective data set of 84 patients and validated on a prospective data set of 45 patients. Plasma levels of CK18 and ccCK18 were assessed by ELISAs. Results: CTCs, tdEVs and both cytokeratin plasma levels were significantly increased in CRPC patients compared to healthy donors (HDs). All biomarkers except for ccCK18 were prognostic showing a decreased median overall survival for the unfavorable groups of 9.2 vs 21.1, 8.1 vs 23.0 and 10.0 vs 21.5 months respectively. In multivariable Cox regression analysis, tdEVs remained significant. Conclusions: Automated CTC and tdEV enumeration allows fast and reliable scoring eliminating inter- and intra- operator variability. tdEVs provide similar prognostic information to CTC counts.},
author = {Nanou, Afroditi and Coumans, Frank A.W. and van Dalum, Guus and Zeune, Leonie L. and Dolling, David and Onstenk, Wendy and Crespo, Mateus and Fontes, Mariane Sousa and Rescigno, Pasquale and Fowler, Gemma and Flohr, Penny and Brune, Christoph and Sleijfer, Stefan and de Bono, Johann S. and Terstappen, Leon W.M.M.},
doi = {10.18632/oncotarget.25019},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Nanou et al. - 2018 - Circulating tumor cells, tumor-derived extracellular vesicles and plasma cytokeratins in castration-resistant pros.pdf:pdf},
issn = {1949-2553},
journal = {Oncotarget},
keywords = {Caspase-cleaved cytokeratin 18 (ccCK18),Castration-resistant prostate cancer (CRPC),Circulating tumor cells (CTCs),Cytokeratin 18 (CK18),Tumor-derived Extracellular Vesicles (tdEVs)},
month = {apr},
number = {27},
pages = {19283--19293},
title = {{Circulating tumor cells, tumor-derived extracellular vesicles and plasma cytokeratins in castration-resistant prostate cancer patients}},
volume = {9},
year = {2018}
}
@inproceedings{Zeune2017,
abstract = {This paper focuses on multi-scale approaches for variational methods and corresponding gradient flows. Recently, for convex regularization functionals such as total variation, new theory and algorithms for nonlinear eigenvalue problems via nonlinear spectral decompositions have been developed. Those methods open new directions for advanced image filtering. However, for an effective use in image segmentation and shape decomposition, a clear interpretation of the spectral response regarding size and intensity scales is needed but lacking in current approaches. In this context, {\$}L{\^{}}1{\$} data fidelities are particularly helpful due to their interesting multi-scale properties such as contrast invariance. Hence, the novelty of this work is the combination of {\$}L{\^{}}1{\$}-based multi-scale methods with nonlinear spectral decompositions. We compare {\$}L{\^{}}1{\$} with {\$}L{\^{}}2{\$} scale-space methods in view of spectral image representation and decomposition. We show that the contrast invariant multi-scale behavior of {\$}L{\^{}}1-TV{\$} promotes sparsity in the spectral response providing more informative decompositions. We provide a numerical method and analyze synthetic and biomedical images at which decomposition leads to improved segmentation.},
address = {Cham},
archivePrefix = {arXiv},
arxivId = {1703.05560},
author = {Zeune, Leonie and van Gils, Stephan A. and Terstappen, Leon W. M. M. and Brune, Christoph},
booktitle = {Scale Space and Variational Methods in Computer Vision: 6th International Conference, SSVM 2017, Kolding, Denmark, June 4-8, 2017, Proceedings},
doi = {10.1007/978-3-319-58771-4_7},
editor = {Lauze, Fran{\c{c}}ois and Dong, Yiqiu and Dahl, Anders Bjorholm},
eprint = {1703.05560},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Zeune et al. - 2017 - Combining Contrast Invariant L1 Data Fidelities with Nonlinear Spectral Image Decomposition.pdf:pdf},
isbn = {978-3-319-58771-4},
keywords = {L 1 -TV,L 1-TV,calibrable sets,denoising,eigenfunctions,multiscale segmentation,nonlinear spectral decom-position,scale-spaces},
month = {mar},
number = {1},
pages = {80--93},
publisher = {Springer International Publishing},
title = {{Combining Contrast Invariant L1 Data Fidelities with Nonlinear Spectral Image Decomposition}},
url = {http://arxiv.org/abs/1703.05560},
year = {2017}
}
@article{Boink2017,
abstract = {Photoacoustic tomography is a hybrid imaging technique that combines high optical tissue contrast with high ultrasound resolution. Direct reconstruction methods such as filtered backprojection, time reversal and least squares suffer from curved line artefacts and blurring, especially in case of limited angles or strong noise. In recent years, there has been great interest in regularised iterative methods. These methods employ prior knowledge on the image to provide higher quality reconstructions. However, easy comparisons between regularisers and their properties are limited, since many tomography implementations heavily rely on the specific regulariser chosen. To overcome this bottleneck, we present a modular reconstruction framework for photoacoustic tomography. It enables easy comparisons between regularisers with different properties, e.g. nonlinear, higher-order or directional. We solve the underlying minimisation problem with an efficient first-order primal-dual algorithm. Convergence rates are optimised by choosing an operator dependent preconditioning strategy. Our reconstruction methods are tested on challenging 2D synthetic and experimental data sets. They outperform direct reconstruction approaches for strong noise levels and limited angle measurements, offering immediate benefits in terms of acquisition time and quality. This work provides a basic platform for the investigation of future advanced regularisation methods in photoacoustic tomography.},
archivePrefix = {arXiv},
arxivId = {1707.02245},
author = {Boink, Yoeri E. and Lagerwerf, Marinus J. and Steenbergen, Wiendelt and van Gils, Stephan A. and Manohar, Srirang and Brune, Christoph},
doi = {10.1088/1361-6560/aaaa4a},
eprint = {1707.02245},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Boink et al. - 2018 - A framework for directional and higher-order reconstruction in photoacoustic tomography(3).pdf:pdf},
issn = {1361-6560},
journal = {Physics in Medicine {\&} Biology},
keywords = {compressive sampling,convex optimisation,directional regularization,photoacoustic tomography,total generalised variation,variational image reconstruction},
month = {jul},
number = {4},
pages = {045018},
title = {{A Framework for Directional and Higher-Order Reconstruction in Photoacoustic Tomography}},
url = {http://arxiv.org/abs/1707.02245},
volume = {63},
year = {2017}
}
@article{Zeune2016,
abstract = {In biomedical imaging reliable segmentation of objects (e.g. from small cells up to large organs) is of fundamental importance for automated medical diagnosis. New approaches for multi-scale segmentation can considerably improve performance in case of natural variations in intensity, size and shape. This paper aims at segmenting objects of interest based on shape contours and automatically finding multiple objects with different scales. The overall strategy of this work is to combine nonlinear segmentation with scales spaces and spectral decompositions recently introduced in literature. For this we generalize a variational segmentation model based on total variation using Bregman distances to construct an inverse scale space. This offers the new model to be accomplished by a scale analysis approach based on a spectral decomposition of the total variation. As a result we obtain a very efficient, (nearly) parameter-free multiscale segmentation method that comes with an adaptive regularization parameter choice. The added benefit of our method is demonstrated by systematic synthetic tests and its usage in a new biomedical toolbox for identifying and classifying circulating tumor cells. Due to the nature of nonlinear diffusion underlying, the mathematical concepts in this work offer promising extensions to nonlocal classification problems.},
archivePrefix = {arXiv},
arxivId = {1604.06665},
author = {Zeune, Leonie and van Dalum, Guus and Terstappen, Leon W.M.M. and van Gils, Stephan A. and Brune, Christoph},
doi = {10.1137/16M1074503},
eprint = {1604.06665},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Zeune et al. - 2016 - Multiscale Segmentation via Bregman Distances and Nonlinear Spectral Analysis.pdf:pdf},
issn = {1936-4954},
journal = {SIAM Journal on Imaging Sciences},
keywords = {1,35a15,35p30,62h35,65k10,68u10,ams subject classifications,bregman iteration,chan-vese method,circulating tumor cells,eigenfunctions,in mathematical imaging the,introduction,inverse scale,inverse scale space,multiscale segmentation,nonlinear spectral methods,problem of segmentation refers,space,to the pro-,total,total variation,variation,wulff shapes},
month = {jan},
number = {1},
pages = {111--146},
title = {{Multiscale Segmentation via Bregman Distances and Nonlinear Spectral Analysis}},
url = {http://arxiv.org/abs/1604.06665},
volume = {10},
year = {2017}
}
@article{Eissa2017,
abstract = {Small-scale neuronal networks may impose widespread effects on large network dynamics. To unravel this relationship, we analyzed eight multiscale recordings of spontaneous seizures from four patients with epilepsy. During seizures, multiunit spike activity organizes into a submillimeter-sized wavefront, and this activity correlates significantly with low-frequency rhythms from electrocorticographic recordings across a 10-cm-sized neocortical network. Notably, this correlation effect is specific to the ictal wavefront and is absent interictally or from action potential activity outside the wavefront territory. To examine the multiscale interactions, we created a model using a multiscale, nonlinear system and found evidence for a dual role for feedforward inhibition in seizures: while inhibition at the wavefront fails, allowing seizure propagation, feedforward inhibition of the surrounding centimeter-scale networks is activated via long-range excitatory connections. Bifurcation analysis revealed that distinct dynamical pathways for seizure termination depend on the surrounding inhibition strength. Using our model, we found that the mesoscopic, local wavefront acts as the forcing term of the ictal process, while the macroscopic, centimeter-sized network modulates the oscillatory seizure activity.},
author = {Eissa, Tahra L. and Dijkstra, Koen and Brune, Christoph and Emerson, Ronald G. and van Putten, Michel J. A. M. and Goodman, Robert R. and McKhann, Guy M. and Schevon, Catherine A. and van Drongelen, Wim and van Gils, Stephan A.},
doi = {10.1073/pnas.1702490114},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Eissa et al. - 2017 - Cross-scale effects of neural interactions during human neocortical seizure activity(3).pdf:pdf},
isbn = {1702490114},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {epilepsy,feedforward inhibition,multiscale interactions,nonlinear dynamics,seizures},
month = {oct},
number = {40},
pages = {10761--10766},
pmid = {28923948},
title = {{Cross-scale effects of neural interactions during human neocortical seizure activity}},
volume = {114},
year = {2017}
}
@article{Zeune2017c,
abstract = {Circulating tumor cells (CTCs) isolated from blood can be probed for the expression of treatment targets. Immunofluorescence is often used for both the enumeration of CTC and the determination of protein expression levels related to treatment targets. Accurate and reproducible assessment of such treatment target expression levels is essential for their use in the clinic. To enable this, an open source image analysis program named ACCEPT was developed in the EU-FP7 CTCTrap and CANCER-ID programs. Here its application is shown on a retrospective cohort of 132 metastatic breast cancer patients from which blood samples were processed by CellSearch {\textregistered} and stained for HER-2 expression as additional marker. Images were digitally stored and reviewers identified a total of 4084 CTCs. CTC's HER-2 expression was determined in the thumbnail images by ACCEPT. 150 of these images were selected and sent to six independent investigators to score the HER-2 expression with and without ACCEPT. Concordance rate of the operators' scoring results for HER-2 on CTCs was 30{\%} and could be increased using the ACCEPT tool to 51{\%}. Automated assessment of HER-2 expression by ACCEPT on 4084 CTCs of 132 patients showed 8 (6.1{\%}) patients with all CTCs expressing HER-2, 14 (10.6{\%}) patients with no CTC expressing HER-2 and 110 (83.3{\%}) patients with CTCs showing a varying HER-2 expression level. In total 1576 CTCs were determined HER-2 positive. We conclude that the use of image analysis enables a more reproducible quantification of treatment targets on CTCs and leads the way to fully automated and reproducible approaches.},
author = {Zeune, Leonie and van Dalum, Guus and Decraene, Charles and Proudhon, Charlotte and Fehm, Tanja and Neubauer, Hans and Rack, Brigitte and Alunni-Fabbroni, Marianna and Terstappen, Leon W. M. M. and van Gils, Stephan A. and Brune, Christoph},
doi = {10.1371/journal.pone.0186562},
editor = {Chalmers, Jeffrey},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Zeune et al. - 2017 - Quantifying HER-2 expression on circulating tumor cells by ACCEPT.pdf:pdf},
issn = {1932-6203},
journal = {PLOS ONE},
month = {oct},
number = {10},
pages = {e0186562},
title = {{Quantifying HER-2 expression on circulating tumor cells by ACCEPT}},
volume = {12},
year = {2017}
}
@inproceedings{Zeune2017b,
author = {Zeune, Leonie L. and van Dalum, Guus and Bidard, Fran{\c{c}}ois-Cl{\'{e}}ment and Pierga, Jean-Yves and Fehm, Tanja and Neubauer, Hans and Rack, Brigitte and Alunni-Fabbroni, Marianna and Crespo, Mateus and de Bono, Johann and Terstappen, Leon W.M.M. and Brune, Christoph},
booktitle = {Conference Abstract, Cancer Research},
doi = {10.1158/1538-7445.AM2017-1733},
issn = {0008-5472},
month = {jul},
number = {13 Supplement},
pages = {1733--1733},
title = {{Automated identification of circulating tumor cells by image analysis}},
volume = {77},
year = {2017}
}
@article{Burg2016,
abstract = {Purpose: Arguments continue as to how the cardiomyocytes are aggregated together within the ventricular walls. We used pneumatic distension through the coronary arteries to exaggerate the gaps between the aggregated cardiomyocytes, analysing the pattern revealed using computed tomography, and validating our finding by histology. Methods: We distended 10 porcine hearts, arresting 4 in diastole by infusion of cardioplegic solutions, and 4 in systole by injection of barium chloride. Mural architecture was revealed by computed tomography, measuring also the angulations of the long chains of cardiomyocytes. We prepared the remaining 2 hearts for histology by perfusion with formaldehyde. Results: Increasing pressures of pneumatic distension elongated the ventricular walls, but produced insignificant changes in mural thickness. The distension exaggerated the spaces between the aggregated cardiomyocytes, compartmenting the walls into epicardial, central, and endocardial regions, with a feathered arrangement of transitions between them. Marked variation was noted in the thicknesses of the parts in the different ventricular segments, with no visible anatomical boundaries between them. Measurements of angulations revealed intruding and extruding populations of cardiomyocytes that deviated from a surface-parallel alignment. Scrolling through the stacks of tomographic images revealed marked spiralling of the aggregated cardiomyocytes when traced from base to apex. Conclusions: Our findings call into question the assumption currently made that the cardiomyocytes are uniformly aggregated together in a tangential fashion. There is marked heterogeneity in the architecture of the different ventricular segments, the aggregated units never extending in fully transmural fashion.},
author = {Burg, M. and Lunkenheimer, P. and Niederer, Peter and Brune, Christoph and Redmann, Klaus and Smerup, Morten and Spiegel, Ulrich and Becker, Felix and Maintz, David and Heindel, Walter and Anderson, R.},
doi = {10.1055/s-0042-115569},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Burg et al. - 2016 - Pneumatic Distension of Ventricular Mural Architecture Validated Histologically(3).pdf:pdf},
issn = {1438-9029},
journal = {R{\"{o}}Fo - Fortschritte auf dem Gebiet der R{\"{o}}ntgenstrahlen und der bildgebenden Verfahren},
keywords = {animal models,heart CT,heart anatomy {\&} histology,myocardial function,myocardium,ventricular stucture},
month = {oct},
number = {11},
pages = {1045--1053},
title = {{Pneumatic Distension of Ventricular Mural Architecture Validated Histologically}},
volume = {188},
year = {2016}
}
@article{Manniesing2016,
abstract = {Brain perfusion is of key importance to assess brain function. Modern CT scanners can acquire perfusion maps of the cerebral parenchyma in vivo at submillimeter resolution. These perfusion maps give insights into the hemodynamics of the cerebral parenchyma and are critical for example for treatment decisions in acute stroke. However, the relations between acquisition parameters, tissue attenuation curves, and perfusion values are still poorly understood and cannot be unraveled by studies involving humans because of ethical concerns. We present a 4D CT digital phantom specific for an individual human brain to analyze these relations in a bottom-up fashion. Validation of the signal and noise components was based on 1,000 phantom simulations of 20 patient imaging data. This framework was applied to quantitatively assess the relation between radiation dose and perfusion values, and to quantify the signal-to-noise ratios of penumbra regions with decreasing sizes in white and gray matter. This is the first 4D CT digital phantom that enables to address clinical questions without having to expose the patient to additional radiation dose.},
author = {Manniesing, Rashindra and Brune, Christoph and van Ginneken, Bram and Prokop, Mathias},
doi = {10.7717/peerj.2683},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Manniesing et al. - 2016 - A 4D CT digital phantom of an individual human brain for perfusion analysis(3).pdf:pdf},
issn = {2167-8359},
journal = {Journal PeerJ},
keywords = {4D CT,Acute stroke,Digital phantom,Perfusion analysis},
month = {nov},
number = {e2683},
pages = {1--19},
title = {{A 4D CT digital phantom of an individual human brain for perfusion analysis}},
volume = {4},
year = {2016}
}
@article{Osting2014,
abstract = {Given a graph where vertices represent alternatives and arcs represent pairwise comparison data, the statistical ranking problem is to find a potential function, defined on the vertices, such that the gradient of the potential function agrees with the pairwise comparisons. Our goal in this paper is to develop a method for collecting data for which the least squares estimator for the ranking problem has maximal Fisher information. Our approach, based on experimental design, is to view data collection as a bi-level optimization problem where the inner problem is the ranking problem and the outer problem is to identify data which maximizes the informativeness of the ranking. Under certain assumptions, the data collection problem decouples, reducing to a problem of finding multigraphs with large algebraic connectivity. This reduction of the data collection problem to graph-theoretic questions is one of the primary contributions of this work. As an application, we study the Yahoo! Movie user rating data set and demonstrate that the addition of a small number of well-chosen pairwise comparisons can significantly increase the Fisher informativeness of the ranking. As another application, we study the 2011-12 NCAA football schedule and propose schedules with the same number of games which are significantly more informative. Using spectral clustering methods to identify highly-connected communities within the division, we argue that the NCAA could improve its notoriously poor rankings by simply scheduling more out-of-conference games.},
author = {Osting, Braxton and Brune, Christoph and Osher, S.J. Stanley J},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Osting, Brune, Osher - 2014 - Optimal Data Collection For Informative Rankings Expose Well-Connected Graphs(2).pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Active learning,Algebraic connectivity,Graph synthesis,Optimal experimental design,Ranking,Scheduling,active learning,algebraic connectivity,graph synthesis,optimal experimental design,ranking,scheduling},
pages = {2981--3012},
title = {{Optimal Data Collection For Informative Rankings Expose Well-Connected Graphs}},
url = {http://jmlr.org/papers/v15/osting14a.html},
volume = {15},
year = {2014}
}
@article{Meyer2014,
abstract = {We propose a novel method to detect and correct drift in non-raster scanning probe microscopy. In conventional raster scanning drift is usually corrected by subtracting a fitted polynomial from each scan line, but sample tilt or large topographic features can result in severe artifacts. Our method uses self-intersecting scan paths to distinguish drift from topographic features. Observing the height differences when passing the same position at different times enables the reconstruction of a continuous function of drift. We show that a small number of self-intersections is adequate for automatic and reliable drift correction. Additionally, we introduce a fitness function which provides a quantitative measure of drift correctability for any arbitrary scan shape.},
author = {Meyer, Travis R. and Ziegler, Dominik and Brune, Christoph and Chen, Alex and Farnham, Rodrigo and Huynh, Nen and Chang, Jen-mei Mei and Bertozzi, Andrea L. and Ashby, Paul D.},
doi = {10.1016/j.ultramic.2013.10.014},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Meyer et al. - 2014 - Height drift correction in non-raster atomic force microscopy(2).pdf:pdf},
isbn = {1879-2723 (Electronic)$\backslash$r0304-3991 (Linking)},
issn = {03043991},
journal = {Journal Ultramicroscopy},
keywords = {Atomic force microscopy,Drift correction,Non-raster scan,Self-intersecting scan,atomic force microscopy,self-intersecting scan},
month = {feb},
pages = {48--54},
pmid = {24295799},
publisher = {Elsevier},
title = {{Height drift correction in non-raster atomic force microscopy}},
volume = {137},
year = {2014}
}
@inproceedings{Frerking2014,
abstract = {The aim of this paper is to track transmigrating leukocytes via TGV flow estimation. Recent results have shown the advantages of the nonlinear and higher order terms of TGV regularizers, especially in static models for denoising and medical reconstruction. We present TGV-based models for flow esti- mation with the goal to get an exact recovery of simple intracellular and extracellular flows, as well as its implication on realistic tracking situations for transmigration through barriers. To study and quantify di ff erent pathways of transmigrating leukocytes, we use large scale 4D fluorescence live microscopy data in vivo.},
address = {Bristol, UK},
author = {Frerking, Lena and Burger, Martin and Vestweber, Dietmar and Brune, Christoph},
booktitle = {IPTA 2014 Inverse Problems - from Theory to Applications, Bristol},
editor = {Louis, Alfred K. and Arridge, Simon and Rundell, Bill},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Louis, Arridge, Rundell - 2014 - Proceedings of the Inverse Problems from Theory to Applications Conference ( IPTA 2014 ).pdf:pdf},
isbn = {9780750311069},
keywords = {Leukocytes,Optical Flow,TGV,Tracking,Transmigration},
number = {August},
pages = {79--83},
publisher = {IOP Publishing},
title = {{TGV-based flow estimation for 4D leukocyte transmigration}},
year = {2014}
}
@incollection{Sawatzky2013,
abstract = {We address the task of reconstructing images corrupted by Poisson noise, which is important in various applications such as fluorescence microscopy (Dey et al., 3D microscopy deconvolution using Richardson-Lucy algorithm with total variation regularization, 2004), positron emission tomography (PET; Vardi et al., J Am Stat Assoc 80:8–20, 1985), or astronomical imaging (Lant{\'{e}}ri and Theys, EURASIP J Appl Signal Processing 15:2500–2513, 2005). Here we focus on reconstruction strategies combining the expectation-maximization (EM) algorithm and total variation (TV) based regularization, and present a detailed analysis as well as numerical results. Recently extensions of the well known EM/Richardson-Lucy algorithm received increasing attention for inverse problems with Poisson data (Dey et al., 3D microscopy deconvolution using Richardson-Lucy algorithm with total variation regularization, 2004; Jonsson et al., Total variation regularization in positron emission tomography, 1998; Panin et al., IEEE Trans Nucl Sci 46(6):2202–2210, 1999). However, most of these algorithms for regularizations like TV lead to convergence problems for large regularization parameters, cannot guarantee positivity, and rely on additional approximations (like smoothed TV). The goal of this lecture is to provide accurate, robust and fast EM-TV based methods for computing cartoon reconstructions facilitating post-segmentation and providing a basis for quantification techniques. We illustrate also the performance of the proposed algorithms and confirm the analytical concepts by 2D and 3D synthetic and real-world results in optical nanoscopy and PET.},
author = {Sawatzky, Alex and Brune, Christoph and K{\"{o}}sters, Thomas and W{\"{u}}bbeling, Frank and Burger, Martin},
booktitle = {Level Set and PDE Based Reconstruction Methods in Imaging: Cetraro, Italy 2008, Editors: Martin Burger, Stanley Osher},
doi = {10.1007/978-3-319-01712-9_2},
editor = {Burger, Martin and Osher, Stanley},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Sawatzky et al. - 2013 - EM-TV Methods for Inverse Problems with Poisson Noise.pdf:pdf},
isbn = {978-3-319-01712-9},
issn = {00758434},
pages = {71--142},
publisher = {Springer International Publishing},
title = {{EM-TV Methods for Inverse Problems with Poisson Noise}},
volume = {2090},
year = {2013}
}
@article{Ziegler2013,
abstract = {Scanning probe microscopy (SPM) has facilitated many scientific discoveries utilizing its strengths of spatial resolution, non-destructive characterization and realistic in situ environments. However, accurate spatial data are required for quantitative applications but this is challenging for SPM especially when imaging at higher frame rates. We present a new operation mode for scanning probe microscopy that uses advanced image processing techniques to render accurate images based on position sensor data. This technique, which we call sensor inpainting, frees the scanner to no longer be at a specific location at a given time. This drastically reduces the engineering effort of position control and enables the use of scan waveforms that are better suited for the high inertia nanopositioners of SPM. While in raster scanning, typically only trace or retrace images are used for display, in Archimedean spiral scans 100{\%} of the data can be displayed and at least a two-fold increase in temporal or spatial resolution is achieved. In the new mode, the grid size of the final generated image is an independent variable. Inpainting to a few times more pixels than the samples creates images that more accurately represent the ground truth.},
author = {Ziegler, Dominik and Meyer, Travis R and Farnham, Rodrigo and Brune, Christoph and Bertozzi, Andrea L and Ashby, Paul D},
doi = {10.1088/0957-4484/24/33/335703},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Ziegler et al. - 2013 - Improved accuracy and speed in scanning probe microscopy by image reconstruction from non-gridded position se(3).pdf:pdf},
issn = {0957-4484},
journal = {Journal Nanotechnology},
language = {en},
month = {aug},
number = {33},
pages = {335703},
pmid = {23892397},
publisher = {IOP Publishing},
title = {{Improved accuracy and speed in scanning probe microscopy by image reconstruction from non-gridded position sensor data}},
volume = {24},
year = {2013}
}
@inproceedings{Osting2013,
abstract = {Given a graph where vertices represent alternatives and pairwise comparison data, yij, is given on the edges, the statistical ranking problem is to find a potential function, defined on the vertices, such that the gradient of the potential function agrees with pairwise comparisons. We study the dependence of the statistical ranking problem on the available pairwise data, i.e., pairs (i,j) for which the pairwise comparison data yij is known, and propose a framework to identify data which, when augmented with the current dataset, maximally increases the Fisher information of the ranking. Under certain assumptions, the data collection problem decouples, reducing to a problem of finding an edge set on the graph (with a fixed number of edges) such that the second eigenvalue of the graph Laplacian is maximal. This reduction of the data collection problem to a spectral graph-theoretic question is one of the primary contributions of this work. As an application, we study the Yahoo! Movie user rating dataset and demonstrate that the addition of a small number of well-chosen pairwise comparisons can significantly increase the Fisher informativeness of the ranking.},
author = {Osting, Braxton and Brune, Christoph and Osher, Stanley},
booktitle = {Proceedings of The 30th International Conference on Machine Learning},
editor = {Dasgupta, Sanjoy and McAllester, David},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Osting, Brune, Osher - 2013 - Enhanced statistical rankings via targeted data collection(3).pdf:pdf},
pages = {489--497},
publisher = {Microtome Publishing},
title = {{Enhanced statistical rankings via targeted data collection}},
url = {http://jmlr.csail.mit.edu/proceedings/papers/v28/osting13.html},
volume = {28},
year = {2013}
}
@article{Benning2013,
author = {Benning, Martin and Brune, Christoph and Burger, Martin and M{\"{u}}ller, Jahn},
doi = {10.1007/s10915-012-9650-3},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Benning et al. - 2013 - Higher-Order TV Methods—Enhancement via Bregman Iteration.pdf:pdf},
issn = {0885-7474},
journal = {Journal of Scientific Computing},
month = {feb},
number = {2-3},
pages = {269--310},
title = {{Higher-Order TV Methods - Enhancement via Bregman Iteration}},
volume = {54},
year = {2013}
}
@inproceedings{Muller2011,
abstract = {We propose a method for reconstructing data from short time positron emission tomography (PET) scans, i.e data acquired over a short time period. In this case standard reconstruction methods deliver only unsatisfactory and noisy results. We incorporate a priori information directly in the reconstruction process via nonlinear variational methods. A promising approach was the so-called EMTV algorithm, where the negative log-likelihood functional, which is minimized in the expectation maximization (ML-EM) algorithm, was modified by adding a total variation (TV) term. To improve the results and to overcome the issue of the loss of contrast we extend the algorithm by an inverse scale space method using Bregman distances, to which we refer as BREGMAN EMTV algorithm. The methods are tested on short time (5 and 30 seconds) FDG measurements of the thorax. We can show that the EMTV approach can effectively reduce the noise, but still introduces an oversmoothing, which is eliminated by the BREGMAN EMTV method, obtaining a reconstruction of comparable quality to the corresponding long time (20 and 7 minutes) scan. This correction for the loss of contrast is necessary to obtain quantitative PET images.},
author = {Muller, Jahn and Brune, Christoph and Sawatzky, Alex and Kosters, Thomas and Schafers, Klaus P and Burger, Martin},
booktitle = {2011 IEEE Nuclear Science Symposium Conference Record},
doi = {10.1109/NSSMIC.2011.6153884},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Muller et al. - 2011 - Reconstruction of short time PET scans using Bregman iterations.pdf:pdf},
isbn = {978-1-4673-0120-6},
issn = {10957863},
keywords = {Algorithm design and analysis,Atmospheric measurements,Bregman iterations,Computational modeling,EMTV algorithm,Particle measurements,a priori information,expectation maximization algorithm,expectation-maximisation algorithm,image reconstruction,medical image processing,negative log-likelihood functional,nonlinear variational method,positron emission tomography,short time PET scan reconstruction,total variation term,variational techniques},
month = {oct},
pages = {2383--2385},
publisher = {IEEE},
shorttitle = {Nuclear Science Symposium and Medical Imaging Conf},
title = {{Reconstruction of short time PET scans using Bregman iterations}},
volume = {1},
year = {2011}
}
@article{Brune2011,
abstract = {Measurements in nanoscopic imaging suffer from blurring effects modeled with different point spread functions (PSF). Some apparatus even have PSFs that are locally dependent on phase shifts. Additionally, raw data are affected by Poisson noise resulting from laser sampling and “photon counts” in fluorescence microscopy. In these applications standard reconstruction methods (EM, filtered backprojection) deliver unsatisfactory and noisy results. Starting from a statistical modeling in terms of a MAP likelihood estimation we combine the iterative EM algorithm with total variation (TV) regularization techniques to make an efficient use of a-priori information. Typically, TV-based methods deliver reconstructed cartoon images suffering from contrast reduction. We propose extensions to EM-TV, based on Bregman iterations and primal and dual inverse scale space methods, in order to obtain improved imaging results by simultaneous contrast enhancement. Besides further generalizations of the primal and dual scale space methods in terms of general, convex variational regularization methods, we provide error estimates and convergence rates for exact and noisy data. We illustrate the performance of our techniques on synthetic and experimental biological data.},
author = {Brune, Christoph and Sawatzky, Alex and Burger, Martin},
doi = {10.1007/s11263-010-0339-5},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Brune, Sawatzky, Burger - 2011 - Primal and Dual Bregman Methods with Application to Optical Nanoscopy(2).pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {Bregman distance,Duality,Error estimation,Image processing,Imaging,Inverse scale space,Poisson noise},
month = {apr},
number = {2},
pages = {211--229},
publisher = {Springer US},
title = {{Primal and Dual Bregman Methods with Application to Optical Nanoscopy}},
volume = {92},
year = {2011}
}
@inproceedings{Dawood2011a,
abstract = {Motion artifacts due to cardiac motion are well known. These artifacts may lead to quantification errors in PET imaging. Using cardiac gating reduces the motion artifacts but increases the noise level due to lesser amount of information per gate. Therefore to use a motion correction scheme to utilize all PET information whereas avoiding the motion artifacts is advisable. In this study a new method of cardiac motion correction on 3D-PET data is presented which is based on mass conserving optical flow.},
address = {Bregenz},
author = {Dawood, Mohammad and Brune, Christoph and B{\"{u}}ther, Florian and Schober, Otmar and Sch{\"{a}}fers, Klaus P},
booktitle = {Nuklearmedizin, Dreil{\"{a}}ndertagung in Bregenz},
editor = {Becherer, A. and M{\"{u}}ller-Brand, J. and Steinbach, J.},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Schmidt et al. - 2011 - Cardiac Motion Correction in 3D PET Data EDV Modelling V57 Improved SPECT MPI rest stress analysis workflow.pdf:pdf},
number = {2},
pages = {A26--A27},
publisher = {Schattauer Publishers},
title = {{A Mass Conservation Based Optical Flow Method for Cardiac Motion Correction in 3D PET Data}},
volume = {50},
year = {2011}
}
@article{Dawood2011,
author = {Dawood, Mohammad and Brune, Christoph and B{\"{u}}ther, Florian and Burger, Martin and Schafers, Michael and Sch{\"{a}}fers, Klaus},
issn = {0161-5505},
journal = {Journal of Nuclear Medicine},
number = {supplement 1},
pages = {107},
publisher = {Society of Nuclear Medicine},
title = {{A mass conservation based optical flow method for combined partial volume and cardiac motion correction in 3D PET}},
url = {http://jnm.snmjournals.org/content/52/supplement{\_}1/107.abstract?sid=6ff58d1a-88b4-4bc1-b39a-2ea389222c14},
volume = {52},
year = {2011}
}
@phdthesis{Brune2010,
abstract = {This thesis contributes to the field of mathematical image processing and inverse problems. An inverse problem is a task, where the values of some model parameters must be computed from observed data. Such problems arise in a wide variety of applications in sciences and engineering, such as medical imaging, biophysics or astronomy. We mainly consider reconstruction problems with Poisson noise in tomography and optical nanoscopy. In the latter case, the task is to reconstruct images from blurred and noisy measurements, whereas in positron emission tomography the task is to visualize physiological processes of a patient. In 3D static image reconstruction standard methods do not incorporate time-dependent information or dynamics, e.g. heart beat or breathing in tomography or cell motion in microscopy. This thesis is a treatise on models, analysis and efficient algorithms to solve 3D and 4D time-dependent inverse problems.},
author = {Brune, Christoph},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Brune - 2010 - 4D imaging in tomography and optical nanoscopy(2).pdf:pdf},
keywords = {4D Bildrekonstruktion,Bregman Distanz,Poisson Rauschen,inverse Probleme,konvexe Splitting Methoden,optimaler Transport,totale Variation},
pages = {1--269},
school = {University of M{\"{u}}nster, Germany},
title = {{4D imaging in tomography and optical nanoscopy}},
type = {PhD thesis},
url = {http://nbn-resolving.de/urn:nbn:de:hbz:6-67429592028},
year = {2010}
}
@incollection{Dawood2010,
address = {Berlin, Heidelberg},
author = {Dawood, Mohammad and Brune, Christoph and Jiang, Xiaoyi and B{\"{u}}ther, Florian and Burger, Martin and Schober, Otmar and Sch{\"{a}}fers, Michael and Sch{\"{a}}fers, Klaus P},
booktitle = {Medical Imaging and Augmented Reality},
doi = {10.1007/978-3-642-15699-1_10},
editor = {Liao, Hongen and Edwards, P J ``Eddie'' and Pan, Xiaochuan and Fan, Yong and Yang, Guang-Zhong},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Burger et al. - 2010 - Method for Cardiac Motion Correction in 3D PET Data(2).pdf:pdf},
isbn = {978-3-642-15699-1},
keywords = {motion},
pages = {88--97},
publisher = {Springer Berlin Heidelberg},
title = {{A Continuity Equation Based Optical Flow Method for Cardiac Motion Correction in 3D PET Data}},
volume = {6326},
year = {2010}
}
@article{Brune2009,
abstract = {In this paper, we propose a new optimization approach for the simultaneous computation of optical flow and edge detection therein. Instead of using an Ambrosio–Tortorelli type energy functional, we reformulate the optical flow problem as a multidimensional control problem. The optimal control problem is solved by discretization methods and large-scale optimization techniques. The edge detector can be immediately built from the control variables. We provide three series of numerical examples. The first shows that the mere presence of a gradient restriction has a regularizing effect, while the second demonstrates how to balance the regularizing effects of a term within the objective and the control restriction. The third series of numerical results is concerned with the direct evaluation of a TV-regularization term by introduction of control variables with sign restrictions.},
author = {Brune, Christoph and Maurer, Helmut and Wagner, Marcus},
doi = {10.1137/080725064},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Brune, Maurer, Wagner - 2009 - Detection of Intensity and Motion Edges within Optical Flow via Multidimensional Control.pdf:pdf},
issn = {1936-4954},
journal = {SIAM Journal on Imaging Sciences},
keywords = {080725064,10,1137,35F30,35R25,35f30,35r25,49J20,49M37,49j20,49m37,68U10,68u10,ams subject classifications,direct methods,doi,edge detection,optical flow,optimal control,optimal control problem,optimization,partial differential equation constrained,partial differential equation constrained optimiza,problem},
language = {en},
month = {jan},
number = {4},
pages = {1190--1210},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Detection of Intensity and Motion Edges within Optical Flow via Multidimensional Control}},
volume = {2},
year = {2009}
}
@incollection{Sawatzky2009,
abstract = {This paper deals with denoising of density images with bad Poisson statistics (low count rates), where the reconstruction of the major structures seems the only reasonable task. Obtaining the structures with sharp edges can also be a prerequisite for further processing, e.g. segmentation of objects. A variety of approaches exists in the case of Gaussian noise, but only a few in the Poisson case. We propose some total variation (TV) based regularization techniques adapted to the case of Poisson data, which we derive from approximations of logarithmic a-posteriori probabilities. In order to guarantee sharp edges we avoid the smoothing of the total variation and use a dual approach for the numerical solution. We illustrate and test the feasibility of our approaches for data in positron emission tomography, namely reconstructions of cardiac structures with 18F-FDG and H215 O tracers, respectively.},
address = {Berlin, Heidelberg},
author = {Sawatzky, Alex and Brune, Christoph and M{\"{u}}ller, Jahn and Burger, Martin},
booktitle = {Computer Analysis of Images and Patterns: 13th International Conference, CAIP 2009, M{\{}{\"{u}}{\}}nster, Germany, September 2-4, 2009. Proceedings},
doi = {10.1007/978-3-642-03767-2_65},
editor = {Jiang, Xiaoyi and Petkov, Nicolai},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Sawatzky et al. - 2009 - Total Variation Processing of Images with Poisson Statistics.pdf:pdf},
isbn = {978-3-642-03767-2},
keywords = {Denoising,Poisson noise,Positron emission tomography,Regularization techniques,Segmentation,Total variation,denoising,poisson noise,positron emission tomography,regularization,segmentation,techniques,total variation},
number = {1},
pages = {533--540},
publisher = {Springer Berlin Heidelberg},
title = {{Total Variation Processing of Images with Poisson Statistics}},
volume = {2},
year = {2009}
}
@incollection{Brune2009a,
abstract = {Measurements in nanoscopic imaging suffer from blurring effects concerning different point spread functions (PSF). Some apparatus even have PSFs that are locally dependent on phase shifts. Additionally, raw data are affected by Poisson noise resulting from laser sampling and ”photon counts” in fluorescence microscopy. In these applications standard reconstruction methods (EM, filtered backprojection) deliver unsatisfactory and noisy results. Starting from a statistical modeling in terms of a MAP likelihood estimation we combine the iterative EM algorithm with TV regularization techniques to make an efficient use of a-priori information. Typically, TV-based methods deliver reconstructed cartoon-images suffering from contrast reduction. We propose an extension to EM-TV, based on Bregman iterations and inverse scale space methods, in order to obtain improved imaging results by simultaneous contrast enhancement. We illustrate our techniques by synthetic and experimental biological data.},
address = {Voss, Norway},
author = {Brune, Christoph and Sawatzky, Alex and Burger, Martin},
booktitle = {Scale Space and Variational Methods in Computer Vision},
doi = {10.1007/978-3-642-02256-2_20},
editor = {Tai, Xue-Cheng and Morken, Knut and Lysaker, Marius and Lie, Knut-Andreas},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Brune, Sawatzky, Burger - 2009 - Bregman-EM-TV Methods with Application to Optical Nanoscopy(3).pdf:pdf},
isbn = {978-3-642-02255-5},
pages = {235--246},
publisher = {Springer Berlin Heidelberg},
title = {{Bregman-EM-TV Methods with Application to Optical Nanoscopy}},
year = {2009}
}
@inproceedings{Sawatzky2008,
author = {Sawatzky, Alex and Brune, Christoph and Wubbeling, Frank and Kosters, Thomas and Schafers, Klaus and Burger, Martin},
booktitle = {2008 IEEE Nuclear Science Symposium Conference Record},
doi = {10.1109/NSSMIC.2008.4774392},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Sawatzky et al. - 2008 - Accurate EM-TV algorithm in PET with low SNR(2).pdf:pdf},
isbn = {978-1-4244-2714-7},
keywords = {Additive noise,Bayesian methods,Expectation maximization algorithm,Gaussian noise,H{\textless}inf{\textgreater}2{\textless}/inf{\textgreater}{\textless}sup{\textgreater}15{\textless}/sup{\textgreater}O measurements,Image reconstruction,Minimization methods,Noise measurement,Nuclear and plasma sciences,PET,Positron emission tomography,Regularization techniques,Signal to noise ratio,TV,Total variation},
month = {oct},
number = {6},
pages = {5133--5137},
publisher = {IEEE},
title = {{Accurate EM-TV algorithm in PET with low SNR}},
year = {2008}
}
@article{Brune2007,
abstract = {In dieser Arbeit besch{\"{a}}ftigen wir uns mit der Berechnung des optischen Flusses einer Sequenz von Bildern. Es handelt sich um eine Bildverarbeitungsaufgabe, die wir sowohl aus Sicht der Mathematik als auch aus Sicht der Informatik studieren. Der optische Fluss ist im Wesentlichen die sichtbare Bewegung, die wir mit unseren Augen wahrnehmen k{\"{o}}nnen. Anhand von Unterschieden in den Intensit{\"{a}}ten bei einer Sequenz gegebener Bilder sind wir in der Lage, auf eine Sch{\"{a}}tzung des optischen Flusses zu schlie{\ss}en.},
author = {Brune, Christoph},
file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Brune - 2007 - Berechnung des Optischen Flusses und Kantenerkennung mit Optimierungsmethoden.pdf:pdf},
institution = {University of M{\"{u}}nster, Germany},
number = {August 2007},
pages = {1--141},
title = {{Berechnung des Optischen Flusses und Kantenerkennung mit Optimierungsmethoden}},
url = {http://wwwmath.uni-muenster.de/num/publications/2007/Bru07/},
year = {2007}
}
