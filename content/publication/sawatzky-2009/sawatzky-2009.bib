@incollection{Sawatzky2009,
 abstract = {This paper deals with denoising of density images with bad Poisson statistics (low count rates), where the reconstruction of the major structures seems the only reasonable task. Obtaining the structures with sharp edges can also be a prerequisite for further processing, e.g. segmentation of objects. A variety of approaches exists in the case of Gaussian noise, but only a few in the Poisson case. We propose some total variation (TV) based regularization techniques adapted to the case of Poisson data, which we derive from approximations of logarithmic a-posteriori probabilities. In order to guarantee sharp edges we avoid the smoothing of the total variation and use a dual approach for the numerical solution. We illustrate and test the feasibility of our approaches for data in positron emission tomography, namely reconstructions of cardiac structures with 18F-FDG and H215 O tracers, respectively.},
 address = {Berlin, Heidelberg},
 author = {Sawatzky, Alex and Brune, Christoph and Müller, Jahn and Burger, Martin},
 booktitle = {Computer Analysis of Images and Patterns: 13th International Conference, CAIP 2009, M\ü\nster, Germany, September 2-4, 2009. Proceedings},
 doi = {10.1007/978-3-642-03767-2_65},
 editor = {Jiang, Xiaoyi and Petkov, Nicolai},
 file = {:Users/brunec/Library/Application Support/Mendeley Desktop/Downloaded/Sawatzky et al. - 2009 - Total Variation Processing of Images with Poisson Statistics.pdf:pdf},
 isbn = {978-3-642-03767-2},
 keywords = {Denoising,Poisson noise,Positron emission tomography,Regularization techniques,Segmentation,Total variation,denoising,poisson noise,positron emission tomography,regularization,segmentation,techniques,total variation},
 number = {1},
 pages = {533--540},
 publisher = {Springer Berlin Heidelberg},
 title = {Total Variation Processing of Images with Poisson Statistics},
 volume = {2},
 year = {2009}
}

